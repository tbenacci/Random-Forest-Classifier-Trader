{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment Information\n",
    "This notebook was originally run using:\n",
    "- **pandas**: 1.4.4\n",
    "- **numpy**: 1.24.2\n",
    "- **scikit-learn**: 1.0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the feature data\n",
    "data = pd.read_csv(\"feature_data_holiday_20251112.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1: Train Years = [2004, 2005, 2006], Validation Years = [2007, 2008], Test Year = 2009\n",
      "Iteration 2: Train Years = [2005, 2006, 2007], Validation Years = [2008, 2009], Test Year = 2010\n",
      "Iteration 3: Train Years = [2006, 2007, 2008], Validation Years = [2009, 2010], Test Year = 2011\n",
      "Iteration 4: Train Years = [2007, 2008, 2009], Validation Years = [2010, 2011], Test Year = 2012\n",
      "Iteration 5: Train Years = [2008, 2009, 2010], Validation Years = [2011, 2012], Test Year = 2013\n",
      "Iteration 6: Train Years = [2009, 2010, 2011], Validation Years = [2012, 2013], Test Year = 2014\n",
      "Iteration 7: Train Years = [2010, 2011, 2012], Validation Years = [2013, 2014], Test Year = 2015\n",
      "Iteration 8: Train Years = [2011, 2012, 2013], Validation Years = [2014, 2015], Test Year = 2016\n",
      "Iteration 9: Train Years = [2012, 2013, 2014], Validation Years = [2015, 2016], Test Year = 2017\n",
      "Iteration 10: Train Years = [2013, 2014, 2015], Validation Years = [2016, 2017], Test Year = 2018\n",
      "Iteration 11: Train Years = [2014, 2015, 2016], Validation Years = [2017, 2018], Test Year = 2019\n",
      "Iteration 12: Train Years = [2015, 2016, 2017], Validation Years = [2018, 2019], Test Year = 2020\n",
      "Iteration 13: Train Years = [2016, 2017, 2018], Validation Years = [2019, 2020], Test Year = 2021\n",
      "Iteration 14: Train Years = [2017, 2018, 2019], Validation Years = [2020, 2021], Test Year = 2022\n",
      "Iteration 15: Train Years = [2018, 2019, 2020], Validation Years = [2021, 2022], Test Year = 2023\n",
      "Iteration 16: Train Years = [2019, 2020, 2021], Validation Years = [2022, 2023], Test Year = 2024\n",
      "Iteration 17: Train Years = [2020, 2021, 2022], Validation Years = [2023, 2024], Test Year = 2025\n",
      "Year 2009: Accuracy = 50.87%, AUC = 0.510\n",
      "Year 2010: Accuracy = 51.65%, AUC = 0.518\n",
      "Year 2011: Accuracy = 50.71%, AUC = 0.509\n",
      "Year 2012: Accuracy = 50.15%, AUC = 0.502\n",
      "Year 2013: Accuracy = 51.67%, AUC = 0.519\n",
      "Year 2014: Accuracy = 51.59%, AUC = 0.509\n",
      "Year 2015: Accuracy = 53.05%, AUC = 0.535\n",
      "Year 2016: Accuracy = 51.18%, AUC = 0.506\n",
      "Year 2017: Accuracy = 50.69%, AUC = 0.509\n",
      "Year 2018: Accuracy = 52.28%, AUC = 0.521\n",
      "Year 2019: Accuracy = 50.78%, AUC = 0.528\n",
      "Year 2020: Accuracy = 53.74%, AUC = 0.536\n",
      "Year 2021: Accuracy = 51.81%, AUC = 0.506\n",
      "Year 2022: Accuracy = 48.34%, AUC = 0.483\n",
      "Year 2023: Accuracy = 51.56%, AUC = 0.504\n",
      "Year 2024: Accuracy = 52.11%, AUC = 0.496\n",
      "Year 2025: Accuracy = 46.33%, AUC = 0.490\n"
     ]
    }
   ],
   "source": [
    "### No Grid Search ###\n",
    "np.random.seed(643)\n",
    "# features and init storage\n",
    "features = [col for col in data.columns if col.startswith(\"char_\")]\n",
    "predictions_by_year = {}\n",
    "accuracy_by_year = {}\n",
    "auc_by_year = {}\n",
    "\n",
    "feature_importance_by_year = {}\n",
    "\n",
    "min_year = data['year'].min()\n",
    "max_year = data['year'].max()\n",
    "counter = 1\n",
    "# loop through the test years using a sequential rolling window of train (3 yr) and validation (2 yr) data\n",
    "for test_year in range(min_year + 5, max_year + 1):\n",
    "    train_years = range(test_year - 5, test_year - 2)\n",
    "    valid_years = range(test_year - 2, test_year)\n",
    "\n",
    "    print(f\"Iteration {counter}: Train Years = {list(train_years)}, Validation Years = {list(valid_years)}, Test Year = {test_year}\")\n",
    "    counter += 1\n",
    "\n",
    "    train_data = data[data['year'].isin(train_years)]\n",
    "    valid_data = data[data['year'].isin(valid_years)]\n",
    "    test_data = data[data['year'] == test_year]\n",
    "\n",
    "    if train_data.empty or valid_data.empty or test_data.empty:\n",
    "        continue\n",
    "    # combine train and validation for final model fit (rf don't require separate sets for training, as bootstrapping occurs)\n",
    "    train_valid_data = pd.concat([train_data, valid_data])\n",
    "\n",
    "    X_train_valid = train_valid_data[features]\n",
    "    y_train_valid = train_valid_data['target']\n",
    "    X_test = test_data[features]\n",
    "    y_test = test_data['target']\n",
    "    # train Random Forest model\n",
    "    model = RandomForestClassifier(\n",
    "        criterion = \"entropy\", # gini v. entropy\n",
    "        n_estimators=2000, # Number of trees in the forest\n",
    "        max_depth=4, # Maximum tree depth\n",
    "        min_samples_leaf=1,\n",
    "        random_state=643,\n",
    "        n_jobs=-1,\n",
    "        max_features=\"sqrt\" # Square root of the number of predictors\n",
    "    )\n",
    "    model.fit(X_train_valid, y_train_valid)\n",
    "    # Feature importance\n",
    "    feature_importance_by_year[test_year] = pd.Series(model.feature_importances_, index=features)\n",
    "    # predict probs and binary classes for test data\n",
    "    test_probs = model.predict_proba(X_test)[:, 1]\n",
    "    # from prior analysis, the target outcomes are nearly 1:1, making 0.5 an appropriate threshold\n",
    "    test_preds = (test_probs >= 0.5).astype(int)\n",
    "    # store probs and calculate metrics\n",
    "    predictions_by_year[test_year] = test_probs.tolist()\n",
    "    accuracy_by_year[test_year] = accuracy_score(y_test, test_preds)\n",
    "    auc_by_year[test_year] = roc_auc_score(y_test, test_probs)\n",
    "# accuracy and AUC for each year\n",
    "for year in sorted(accuracy_by_year.keys()):\n",
    "    print(f\"Year {year}: Accuracy = {accuracy_by_year[year]:.2%}, AUC = {auc_by_year[year]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Grid Search Method ###\n",
    "np.random.seed(643)\n",
    "# Features and initialization\n",
    "features = [col for col in data.columns if col.startswith(\"char_\")]\n",
    "predictions_by_year = {}\n",
    "accuracy_by_year = {}\n",
    "auc_by_year = {}\n",
    "feature_importance_by_year = {}\n",
    "\n",
    "min_year = data['year'].min()\n",
    "max_year = data['year'].max()\n",
    "\n",
    "counter = 1\n",
    "# Rolling loop\n",
    "for test_year in range(min_year + 5, max_year + 1):\n",
    "    train_years = range(test_year - 5, test_year - 2)\n",
    "    valid_years = range(test_year - 2, test_year)\n",
    "\n",
    "    print(f\"Iteration {counter}: Train Years = {list(train_years)}, Validation Years = {list(valid_years)}, Test Year = {test_year}\")\n",
    "    counter += 1\n",
    "\n",
    "    train_data = data[data['year'].isin(train_years)]\n",
    "    valid_data = data[data['year'].isin(valid_years)]\n",
    "    test_data = data[data['year'] == test_year]\n",
    "\n",
    "    if train_data.empty or valid_data.empty or test_data.empty:\n",
    "        continue\n",
    "\n",
    "    X_train = train_data[features]\n",
    "    y_train = train_data['target']\n",
    "    X_valid = valid_data[features]\n",
    "    y_valid = valid_data['target']\n",
    "    X_test = test_data[features]\n",
    "    y_test = test_data['target']\n",
    "    # Combine for final model fit after tuning\n",
    "    X_train_valid = pd.concat([X_train, X_valid])\n",
    "    y_train_valid = pd.concat([y_train, y_valid])\n",
    "    # Grid search on train + valid\n",
    "    param_grid = {\n",
    "        'n_estimators': [250, 500, 1000],\n",
    "        'max_depth': [5, 7, 9],\n",
    "        'min_samples_leaf': [1, 3, 5],\n",
    "        'max_features': ['sqrt']\n",
    "    }\n",
    "\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=RandomForestClassifier(random_state=643, n_jobs=-1),\n",
    "        param_grid=param_grid,\n",
    "        cv=3,\n",
    "        scoring='roc_auc',\n",
    "        verbose=3\n",
    "    )\n",
    "\n",
    "    grid_search.fit(X_train_valid, y_train_valid)\n",
    "    best_params = grid_search.best_params_\n",
    "    # Train model with best hyperparameters\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=best_params['n_estimators'],\n",
    "        max_depth=best_params['max_depth'],\n",
    "        max_features=best_params['max_features'],\n",
    "        min_samples_leaf=1,\n",
    "        random_state=643,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    model.fit(X_train_valid, y_train_valid)\n",
    "    # Feature importance\n",
    "    feature_importance_by_year[test_year] = pd.Series(model.feature_importances_, index=features)\n",
    "    # Predictions\n",
    "    test_probs = model.predict_proba(X_test)[:, 1]\n",
    "    test_preds = (test_probs >= 0.5).astype(int)\n",
    "    # Store results\n",
    "    predictions_by_year[test_year] = test_probs.tolist()\n",
    "    accuracy_by_year[test_year] = accuracy_score(y_test, test_preds)\n",
    "    auc_by_year[test_year] = roc_auc_score(y_test, test_probs)\n",
    "# Print accuracy and AUC by year\n",
    "for year in sorted(accuracy_by_year.keys()):\n",
    "    print(f\"Year {year}: Accuracy = {accuracy_by_year[year]:.2%}, AUC = {auc_by_year[year]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten predictions into one list\n",
    "all_predictions = [prob for year_probs in predictions_by_year.values() for prob in year_probs]\n",
    "# get all test data (years with predictions available)\n",
    "test_data = data[data['year'] >= (min_year + 5)].copy()\n",
    "# make sure predictions are flattened into a single list (predictions_by_year is in order)\n",
    "all_predictions = []\n",
    "for year in sorted(predictions_by_year.keys()):\n",
    "    all_predictions.extend(predictions_by_year[year])\n",
    "# length matches the number of test rows\n",
    "if len(all_predictions) != len(test_data):\n",
    "    raise ValueError(f\"Length mismatch: {len(all_predictions)} predictions vs {len(test_data)} test rows\")\n",
    "# make prediction column\n",
    "test_data['prediction'] = all_predictions\n",
    "rf_results_df = test_data[['datadate', 'year', 'tic', 'holiday_return', 'spy_holiday_return', 'target', 'prediction']]\n",
    "# save as csv file\n",
    "rf_results_df.to_csv(\"rf_holiday_results_20251120v3_entropy.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
